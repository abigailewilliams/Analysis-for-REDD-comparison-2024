---
title: "Code for Analysis 1 & 2"
date: 
output: 
  html_document: default
  pdf_document: default
---

# Introduction

This analysis compares certified estimates of avoided deforestation using VERRA methods with statisical assessments using matching approaches.

The analysis makes use of:

-   Supplementary data from West 2023

-   Non-public supplementary data from Guizar-Coutino 2022

-   Non-public supplementary data from West 2020

-   Data from PACT analyses

-   Data extracted from public documents accessed via the VERRA registry

For the original published articles please see

-   [West et al. (2020](https://www.pnas.org/doi/full/10.1073/pnas.2004334117))
-   [Guizar-Coutino et al. (2022](https://conbio.onlinelibrary.wiley.com/doi/10.1111/cobi.13970))
-   [West et al. (2023](https://www.science.org/doi/10.1126/science.ade3535))
-   [Guizar-Coutino et al. (2024](https://www.biorxiv.org/content/10.1101/2024.05.22.595326v2))
-   [West et al. (2024](https://www.sciencedirect.com/science/article/pii/S0959378024000670))
-   [PACT](https://www.cambridge.org/engage/coe/article-details/657c8b819138d23161bb055f)

Code for producing the data used as inputs to our paper is available:

-   [Guizar-Coutino et al. (2024](https://github.com/guizar/redd-sens))

We're present avoided deforestation in hectares per year

```{r setup, include=FALSE, echo = FALSE}
# clean and load packages
rm(list=ls())
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
# library
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggrepel)
library(cowplot)
library(magrittr)
library(RColorBrewer)
library(weights)
library(GGally)


theme_set(theme_classic())

my_colors<-colorRampPalette(brewer.pal(9,'BuGn'))(10)[c(4,6,8,10)]

data_path<-'../data/analysis_1_2'
output_path<-'../outputs'
fig_path<-'../figures'

if(!dir.exists(fig_path))
  dir.create(fig_path)

if(!dir.exists(output_path))
  dir.create(output_path)

```

# Load and align assessment data

Read in data from West et al. 2024

```{r}

tw1<-read.csv(file.path(data_path, 'TW_2024_1.csv'))
tw2<-read.csv(file.path(data_path, 'TW_2024_2.csv'))
tw3<-read.csv(file.path(data_path, 'TW_2024_3.csv')) #  tw3 seems to be a subset of tw1

# extract just the bit which is unique:
tw3_subset <- tw3 %>% filter(project == 'Project 1112 (VM0007)', 
                             vm %in% c('VM0007-MLP', 'VM0015-MLP'),
                             year >=2016) 

ID<-c(1112, 1396, 934, 944)
year_start<-c(2012, 2014, 2012, 2009)
year_end<-c(2017, 2020, 2020, 2018)
tw_start_end<-data.frame(ID, year_start, year_end)

tw<-rbind(tw1, tw2, tw3_subset) %>%
  rename(ID = project) %>%
  mutate(ID = case_when(
    ID == 'Project 1112 (VM0007)'~ 1112, 
    ID == 'Project 1396 (VM0006)'~ 1396,
    ID == 'Project 934 (VM0009)'~ 934,
    ID == 'Project 944 (VM0015)'~ 944)
    ) %>%
  inner_join(tw_start_end)

tw %>% 
  filter(vm == 'Official baseline') %>%
  group_by(ID) %>%
  summarise(year_start = min(year),
            year_end = max(year))
  
  
tw_avd_def<-tw %>%
  mutate(ID = as.factor(ID)) %>%
  filter(!(is.na(def))) %>%
  group_by(ID, vm) %>%
  mutate(vm = case_when(
    str_detect(vm, 'Official')~ 'official',
    str_detect(vm, 'Observed deforestation')~'observed',
    str_detect(vm, 'Ex-post')~'SC',
    TRUE~ as.character(vm))
  ) %>%
  summarise(year_start = year_start[1], year_end = year_end[1], def = (def[year == year_end] - def[year == year_start])) %>% # cumulative deforestation to deforestation
  ungroup()

# export the synthetic control estimates for use in analysis 1:
tw_avd_def %>%
  filter(vm == "SC") %>%
  write.csv(file.path(output_path, '/TW_2024_SC.csv'))
```


```{r data prep, include = FALSE, echo = FALSE}

# read in inputs

# Statistical assessments
tw_20 <- read.csv(file.path(data_path, "TW_2020.csv"))
tw_23 <- read.csv(file.path(data_path, "TW_2023.csv"))
tw_24 <- read.csv(file.path(output_path, "TW_2024_SC.csv"))
ag_22 <- read.csv(file.path(data_path, "AG_2022.csv"))
ag_24 <- read.csv(file.path(data_path, "AG_2024.csv")) %>%
  select(ID = vcs_id, Avd_def = DD_ha) %>%
  mutate(ID = as.numeric(str_replace(ID, 'PL', ''))) %>%
  mutate(Avd_def = -Avd_def)
pact_v2 <- read.csv(file.path(data_path, "project_summaries.csv")) %>%
  filter(ID != '1325') %>%
  rename(cv = cov_avoided_disturbance_prop,
         Start = start,
         End = end,
         ID = id) %>% 
  filter(cv <0.5) # filter out those projects with a large coefficient of variance (>50% of mean estimte) 
                  # across the bootstraps indicating non convergence
# Certified assessments
vcs <- as.data.frame(read.csv(file.path(data_path,'certified.csv')))

```

Align certified assessment data format with statistical

```{r}
vcs$total.avoided.def[which(vcs$total.avoided.def =="#VALUE!"|vcs$total.avoided.def =="")] <- NA
vcs$total.additionality[which(vcs$total.additionality =="#VALUE!"|vcs$total.additionality =="")] <- NA
vcs$raw.additionality[which(vcs$raw.additionality =="#VALUE!"|vcs$raw.additionality =="")] <- NA

vcs$total.avoided.def <- as.numeric(vcs$total.avoided.def)
vcs$total.additionality <- as.numeric(vcs$total.additionality)
vcs$raw.additionality <- as.numeric(vcs$raw.additionality)
vcs$def.emissions.ONLY <- as.numeric(vcs$def.emissions.ONLY)
vcs$Start <- as.numeric(vcs$Start)
vcs$End <- as.numeric(vcs$End)

```

Combine datasets

```{r}
# align the datasets

vcs %<>%
  select(c("ID", "Start", "End", "total.avoided.def"))  %>% 
  rename(Avd_def = total.avoided.def) %>%
  mutate(source = "VERRA", 
         label = "VERRA")

tw_20 <- tw_20 %>% 
  select(c("ID", "start", "end", "avd_def")) %>% 
  rename(Start = start, End = end, Avd_def = avd_def) %>%
  mutate(source = "TW_2020",
         label = "West 20")

tw_23 %<>% 
  select(c("ID", "Start", "End", "Avoided_def")) %>% 
  rename(Avd_def = Avoided_def) %>%
  mutate(source = "TW_2023",
         label = "West 23")

tw_24 %<>% 
  select(ID, Start = year_start, End = year_end, Avd_def = def) %>% 
  filter(ID == 934) %>%
  mutate(source = "TW_2023", # this project is not actually in west 2023 but is in West 2024; combined with 2023 for simplicty
         label = "West 23")

ag_22$Start <- 0
ag_22$End <- 5
ag_22<-ag_22 %>% 
  select(ID, Start, End, Avoided_def) %>% 
  rename(Avd_def = Avoided_def) %>%
  mutate(source = "AG_2022",
         label = "Guizar-Coutino 22")

ag_24 %<>%
  mutate(Start = 0, End = 5) %>% 
  select(c("ID", "Start", "End", "Avd_def")) %>%
  mutate(source = "AG_2024",
         label = "Guizar-Coutino 24")

pact_v2 %<>% 
  select(c("ID", "Start", "End", "avoided_disturbance_ha")) %>% 
  rename(Avd_def = avoided_disturbance_ha) %>%
  mutate(source = "PACTv2", 
         label = "PACTv2")

# combine
df <- rbind(tw_20, tw_23, tw_24, ag_22, ag_24, pact_v2, vcs) %>%
  mutate(ID = as.factor(ID)) %>%
  mutate(avd_def_yr = Avd_def / (End - Start))

```

```{r}
# read project method and country information and combine

all_projects <- read.csv(file.path(data_path, "Project_country_method.csv")) %>%
  select(ID, method = Methodology, country = Country.Area)

# project area

df %<>% 
  left_join(all_projects %>% mutate(ID = as.factor(ID))) %>%
  # left_join(all_areas %>% mutate(ID = as.factor(ID))) %>%
  # set factor class  
  mutate(
    source = as.factor(source),
    label = as.factor(label),
    method = as.factor(method),
    country = as.factor(country)
    # avd_def_yr_ha = avd_def_yr / area_ha,
    # add_yr_ha = add_yr / area_ha, 
    ) %>%
  mutate(counterfactual = ifelse(source == 'VERRA', 0, 1))

# Filter only to unplanned deforestation methodologies
df %<>% filter(method %in% c('VM0006', 'VM0007', 'VM0009', 'VM0015') )

write.csv(df, file.path(output_path, '/combined.csv'))

```

Aligning the data so that each statistical assessment is matched to the corresponding certified assessment

```{r CF vs. Verra prep, echo = FALSE}

cf_vcs_comp_def <- df %>% 
  select(ID, avd_def_yr, source) %>%
  group_by(ID) %>% 
  pivot_wider(names_from = source, values_from = avd_def_yr) %>% 
  filter(!is.na(VERRA)) %>% 
  pivot_longer(cols = c(-ID, -VERRA), names_to = "cf_source", values_to = "cf_avd") %>%
  ungroup() %>%
  filter(!is.na(cf_avd)) %>%
  # mutate(Aadj= cf_avd / VERRA)
  mutate(Aadj= cf_avd / VERRA)


cf_vcs_comp_def$cf_source <- as.factor(cf_vcs_comp_def$cf_source)

write.csv(cf_vcs_comp_def, file.path(output_path, 'certified_statistical_comparison.csv'))
```


# Numbers of projects evaluated by each study

```{r}

unique_projects<-cf_vcs_comp_def %>% 
  filter(cf_source %in% c('TW_2020', 'TW_2023', 'AG_2022', 'AG_2024', 'PACTv2')
         ) %>% pull(ID) %>% unique()

(n_projects<-length(unique_projects))

unique_projects %>% as.character() %>% as.numeric() %>% sort()

cat('VM0006: ', df %>% 
  filter(ID %in% unique_projects,
         method == 'VM0006') %>% pull(ID) %>% unique() %>% sort() %>% length()
)
cat('VM0007: ', df %>% 
  filter(ID %in% unique_projects,
         method == 'VM0007') %>% pull(ID) %>% unique() %>% sort() %>% length()
)

cat('VM0009: ', df %>% 
  filter(ID %in% unique_projects,
         method == 'VM0009') %>% pull(ID) %>% unique() %>% sort() %>% length()
)

cat('VM00015: ', df %>% 
  filter(ID %in% unique_projects,
         method == 'VM0015') %>% pull(ID) %>% unique() %>% sort() %>% length()
)

cat('TW_2020: ', cf_vcs_comp_def %>% 
  filter(cf_source == 'TW_2020',
         !is.na(VERRA)) %>%
  nrow()
)

cat('TW_2023: ', cf_vcs_comp_def %>% 
  filter(cf_source == 'TW_2023',
         !is.na(VERRA)) %>%
  nrow()
)

cat('AG_2022: ', cf_vcs_comp_def %>% 
  filter(cf_source == 'AG_2022',
         !is.na(VERRA)) %>%
  nrow()
)

cat('AG_2024: ', cf_vcs_comp_def %>% 
  filter(cf_source == 'AG_2024',
         !is.na(VERRA)) %>%
  nrow()
)

cat('PACT: ', cf_vcs_comp_def %>% 
  filter(cf_source == 'PACTv2',
         !is.na(VERRA)) %>%
  nrow()
)

```

# Fig 1. Comparative analysis of overcrediting

Calculate the summary statistics for each project

```{r}
cf_vcs_avd_comp_mean<-cf_vcs_comp_def %>% 
  group_by(ID) %>%
  summarise(n = n(),
            cf_avd_mean = mean(cf_avd),
            cf_avd_min = min(cf_avd),
            cf_avd_max = max(cf_avd),
            cf_avd_sd = sd(cf_avd),
            cf_avd_se = cf_avd_sd / sqrt(n),
            cf_avd_ci = 1.96*cf_avd_se, # calculate CI
            cf_avd_ci_min = cf_avd_mean - cf_avd_ci, # CI min
            cf_avd_ci_max = cf_avd_mean + cf_avd_ci, # CI max
            cf_Aadj_mean = mean(Aadj),
            cf_Aadj_min = min(Aadj),
            cf_Aadj_max = max(Aadj),
            cf_Aadj_sd = sd(Aadj), # add SD
            cf_Aadj_se = cf_Aadj_sd / sqrt(n), # add SE
            cf_Aadj_ci = 1.96*cf_Aadj_se, # calculate CI
            cf_Aadj_ci_min = cf_Aadj_mean - cf_Aadj_ci, # CI min
            cf_Aadj_ci_max = cf_Aadj_mean + cf_Aadj_ci, # CI max
            VERRA  = VERRA[1])

write.csv(cf_vcs_avd_comp_mean, file.path(output_path, 'certified_statistical_AddRatio.csv'),row.names=F)

```

## Fig 1a. Certified vs statistical assessements of avoided deforestation by project. 

The dashed line shows a 1:1 relationship between X and Y. Projects above the line are assessed to have overcredited.

```{r}

plot(cf_vcs_avd_comp_mean$VERRA, cf_vcs_avd_comp_mean$cf_avd_mean)

cor.test(cf_vcs_avd_comp_mean$VERRA, cf_vcs_avd_comp_mean$cf_avd_mean)

new.dat = data.frame(cf_avd_mean = seq(from = min(cf_vcs_avd_comp_mean$cf_avd_min), to = max(cf_vcs_avd_comp_mean$cf_avd_max, by = 1))) %>%
  mutate(VERRA = cf_avd_mean)

cf_vcs_avd_comp_mean %>%
  # filter(n>=2) %>%
  ggplot(aes(y = VERRA, x = cf_avd_mean)) +
  # geom_abline(intercept = 0, slope = 1, col = "black", linetype = 2, linewidth = 0.75)+
  geom_line(data = new.dat, col = "black", linetype = 2, linewidth = 0.75)+
  # geom_line(data = df_abline, col = "grey", linetype = 2, linewidth = 0.75)+
  geom_vline(xintercept = 0, col = "black", linetype = 1, linewidth = 0.5)+
  geom_hline(yintercept = 0, col = "black", linetype = 1, linewidth = 0.5)+
  # geom_smooth(method = 'lm', formula = y~x,  se = FALSE, col = 'black', linewidth = 0.75)+
  geom_point(size = 3, alpha = 0.8, aes(color = as.factor(n)))+
  geom_errorbar(aes(xmin = cf_avd_ci_min, 
                    xmax = cf_avd_ci_max, color = as.factor(n))) +
  # geom_errorbar(aes(xmin = cf_avd_mean - cf_avd_se, xmax = cf_avd_mean + cf_avd_se, color = as.factor(n))) +
  # scale_x_continuous(trans='log10') +
  scale_x_continuous(limits = c(-1000, 3500)) +
  scale_y_continuous(trans='log10', limits = c(50, 10000)) +
  scale_color_manual(values = my_colors,
                    labels = c("1", "2","3","4")) +
  # geom_errorbar(aes(xmin = cf_add_mean - cf_add_se, xmax = cf_add_mean + cf_add_se, color = as.factor(n))) +
  # geom_text_repel(aes(label = ID, color = as.factor(n)), size = 3, nudge_x = 1, nudge_y = 1, max.overlaps = 20)+
  ylab("Self-reported avoided deforestation (ha/yr)") + xlab("Independent assessment of avoided deforestation (ha/yr)")+
  # theme_classic() +
  # xlim(0, 3100) + # so that the xaxis labels fit in properly
  theme(axis.line = element_blank(),
        axis.text = element_text(size = 12),
        legend.position="bottom",
        legend.spacing = unit(0, "cm")
        ) +
  guides(shape = guide_legend(ncol=2, bycol=TRUE, title = NULL,
                              override.aes = list(size = 4, col = "black")),
         color = guide_legend(ncol=4, bycol=TRUE, title = "Number of studies", 
                             override.aes = list(shape = 16, size = 3, alpha = 0.5)))

ggsave(file.path(fig_path, 'Fig1a.png'), bg = 'white',
       width = 6, # 7
       height = 4,# 5
       units = 'in')
```
# Version of the above figure with points coloured by country.

```{r}

all_projects$ID <- as.factor(all_projects$ID)

df_for_plot <- cf_vcs_avd_comp_mean %>%
  mutate(ID = as.factor(ID)) %>% 
  inner_join(all_projects, by = "ID")

df_for_plot %>% 
  ggplot(aes(y = VERRA, x = cf_avd_mean, colour = country)) +
  geom_abline(intercept = 0, slope = 1, col = "black", linetype = 2, linewidth = 0.75)+
  geom_line(data = new.dat, col = "black", linetype = 2, linewidth = 0.75)+
  geom_vline(xintercept = 0, col = "black", linetype = 1, linewidth = 0.5)+
  geom_hline(yintercept = 0, col = "black", linetype = 1, linewidth = 0.5)+
  geom_point(size = 3, alpha = 0.8)+
  scale_x_continuous(limits = c(-1000, 3500)) +
  scale_y_continuous(trans='log10', limits = c(50, 10000)) +
  ylab("Self-reported avoided deforestation (ha/yr)") + xlab("Independent assessment of avoided deforestation (ha/yr)")+
  theme(axis.line = element_blank(),
        axis.text = element_text(size = 12),
        legend.position="right",
        legend.spacing = unit(0, "cm")
        )

```



```{r}
# VERRA avoideded deforestation against matched counterfactual avoided deforestation 


cf_vcs_avd_comp_mean %<>% 
  mutate(log_VERRA = log10(VERRA), 
         log_cf_Aadj_mean = log10(cf_Aadj_mean))
fm_2_1<-lm(cf_Aadj_mean~log_VERRA, data = cf_vcs_avd_comp_mean)
# fm_2_1<-lm(log_cf_Aadj_mean~log_VERRA, data = cf_vcs_avd_comp_mean %>% filter(!is.infinite(cf_Aadj_mean)))
summary(fm_2_1)

hist(cf_vcs_avd_comp_mean$cf_Aadj_mean, breaks = 10)
shapiro.test(cf_vcs_avd_comp_mean$cf_Aadj_mean)
wilcox.test(cf_vcs_avd_comp_mean$cf_Aadj_mean, mu = 0, paired = FALSE, alternative = "greater")
wilcox.test(cf_vcs_avd_comp_mean$cf_Aadj_mean, mu = 1, paired = FALSE, alternative = "less")
length(cf_vcs_avd_comp_mean$cf_Aadj_mean)

# Mean overcrediting
(Aadj_mean<-mean(cf_vcs_avd_comp_mean$cf_Aadj_mean))
(Aadj_w_mean<-weighted.mean(cf_vcs_avd_comp_mean$cf_Aadj_mean, cf_vcs_avd_comp_mean$VERRA))
1/Aadj_mean *100
1/Aadj_w_mean *100

```
## Fig 1b. Additionality ratio vs statistical assessements of avoided deforestation by project. 

```{r}



cf_vcs_avd_comp_mean %>%
  mutate(Aadj_mean =  cf_avd_mean / VERRA) %>% 
  # mutate(Aadj_mean = ifelse(Aadj_mean <0, Inf, Aadj_mean)) %>%
  # rename(Aadj = Aadj_mean) %>%
  # filter(VERRA>0) %>%
  # filter(!is.infinite(Aadj)) %>%
  # filter(n>=2) %>%
  ggplot(aes(x = VERRA, y = Aadj_mean, label = ID)) +
  geom_vline(xintercept = 0, col = "black", linetype = 1, linewidth = 0.5)+
  geom_hline(yintercept = 0, col = "black", linetype = 1, linewidth = 0.5)+
  geom_hline(yintercept = 1, col = "black", linetype = 2, linewidth = 0.75)+
  geom_hline(yintercept = Aadj_mean, linewidth = 0.75, col = 'grey')+
  geom_hline(yintercept = Aadj_w_mean, linewidth = 0.75, col = 'grey', linetype = 2)+
  # geom_smooth(method = 'lm', formula = y~x)+
  #geom_hline(yintercept = cf_Aadj_mean, linewidth = 0.75, col = 'grey')+
  geom_point(size = 3, alpha = 0.8, aes(color = as.factor(n)))+
  geom_errorbar(aes(ymin = cf_Aadj_ci_min, ymax = cf_Aadj_ci_max, color = as.factor(n))) +
  # geom_text_repel(aes(color = as.factor(n)), size = 3, max.overlaps = 20)+
  scale_color_manual(values = my_colors,
                    labels = c("1", "2","3","4")) +
  xlab("Self-reported avoided deforestation (ha/yr)") + ylab("Additionality ratio")+
  # scale_y_continuous(trans='log10') +
  scale_x_continuous(trans='log10') +
  theme(axis.line = element_blank(),
        axis.text = element_text(size = 12),
        legend.position="bottom",
        legend.spacing = unit(0, "cm")) +
  guides(shape = guide_legend(ncol=2, bycol=TRUE, title = NULL,
                              override.aes = list(size = 4, col = "black")),
         color = guide_legend(ncol=4, bycol=TRUE, title = "Number of studies", 
                             override.aes = list(shape = 16, size = 3, alpha = 0.5)))



ggsave(file.path(fig_path, 'Fig1b.png'), bg = 'white',
       width = 5, # 7
       height = 4,# 5
       units = 'in')



```

## Fig 1b. Additionality ratio vs statistical assessements of avoided deforestation by project labelled by projct ID. 


```{r}

cf_vcs_avd_comp_mean %>%
  mutate(Aadj_mean =  cf_avd_mean / VERRA) %>% 
  # mutate(Aadj_mean = ifelse(Aadj_mean <0, Inf, Aadj_mean)) %>%
  # rename(Aadj = Aadj_mean) %>%
  # filter(VERRA>0) %>%
  # filter(!is.infinite(Aadj)) %>%
  # filter(n>=2) %>%
  ggplot(aes(x = VERRA, y = Aadj_mean, label = ID)) +
  geom_vline(xintercept = 0, col = "black", linetype = 1, linewidth = 0.5)+
  geom_hline(yintercept = 0, col = "black", linetype = 1, linewidth = 0.5)+
  geom_hline(yintercept = 1, col = "black", linetype = 2, linewidth = 0.75)+
  # geom_smooth(method = 'lm', formula = y~x)+
  geom_hline(yintercept = Aadj_mean, linewidth = 0.75, col = 'grey')+
  geom_hline(yintercept = Aadj_w_mean, linewidth = 0.75, col = 'grey', linetype = 2)+
  geom_point(size = 3, alpha = 0.8, aes(color = as.factor(n)))+
  geom_errorbar(aes(ymin = cf_Aadj_ci_min, ymax = cf_Aadj_ci_max, color = as.factor(n))) +
  geom_text_repel(aes(color = as.factor(n)), size = 3, max.overlaps = 20)+
  scale_color_manual(values = my_colors,
                    labels = c("1", "2","3","4")) +
  xlab("Self-reported avoided deforestation (ha/yr)") + ylab("Additionality ratio")+
  # scale_y_continuous(trans='log10') +
  scale_x_continuous(trans='log10') +
  theme(axis.line = element_blank(),
        axis.text = element_text(size = 12),
        legend.position="bottom",
        legend.spacing = unit(0, "cm")) +
  guides(shape = guide_legend(ncol=2, bycol=TRUE, title = NULL,
                              override.aes = list(size = 4, col = "black")),
         color = guide_legend(ncol=4, bycol=TRUE, title = "Number of studies", 
                             override.aes = list(shape = 16, size = 3, alpha = 0.5)))

ggsave(file.path(fig_path, 'Fig1b_IDlabels.png'), bg = 'white',
       width = 5, # 7
       height = 4,# 5
       units = 'in')

```
Summary stats reported

```{r}

print('Achieved avoided deforestation')
cf_vcs_avd_comp_mean %>% filter(cf_Aadj_mean >0)
df %>% filter(ID %in% (cf_vcs_avd_comp_mean %>% filter(cf_Aadj_mean >1) %>% pull(ID)))

print('Undercrediting')
cf_vcs_avd_comp_mean %>% filter(cf_Aadj_mean >1)
under_projects<-df %>% filter(ID %in% (cf_vcs_avd_comp_mean %>% filter(cf_Aadj_mean >1) %>% pull(ID)))
under_projects
nrow(under_projects) / n_projects

print('Overcrediting')
over_projects<-cf_vcs_avd_comp_mean %>% filter(cf_Aadj_mean <1)
over_projects
nrow(over_projects) / n_projects

print('Negative or no additionality')
cf_vcs_avd_comp_mean %>% filter(cf_Aadj_mean <=0) %>% mutate(ID = as.numeric(as.character(ID))) %>% arrange(ID)
df %>% filter(ID %in% (cf_vcs_avd_comp_mean %>% filter(cf_Aadj_mean <=0) %>% pull(ID)))

print('Projects issuing too many credits')
big_issuing_projects<-cf_vcs_avd_comp_mean %>% filter(VERRA >2500)
nrow(big_issuing_projects)

```
# Fig 2

Setup the format for the West 2024 data. Summarised so that the response is in ha / year

```{r}
tw_avd_def_yr <- tw_avd_def %>%
  pivot_wider(names_from = vm, values_from = def) %>%
  mutate(across(SC | official | starts_with("VM"), ~ (.x - observed) / (year_end - year_start))) %>% # calculate avoided deforestation in ha / year
  pivot_longer(cols = SC| official | starts_with("VM"), names_to = 'methodology', values_to = 'avd_def_yr') %>%
  select(-observed) %>%
  mutate(ID = as.numeric(as.character(ID)))


tw_summary <- tw_avd_def_yr %>%
  group_by(ID) %>%
  mutate(n = sum(!is.na(avd_def_yr))) %>%
  summarise(vcs_official = avd_def_yr[methodology =='official'],
            vcs_mean = mean(avd_def_yr, na.rm = TRUE),
            vcs_min = min(avd_def_yr, na.rm = TRUE),
            vcs_max = max(avd_def_yr, na.rm = TRUE),
            vcs_sd = sd(avd_def_yr, na.rm = TRUE),
            vcs_se = vcs_sd / sqrt(n[1]),
            vcs_cv = vcs_sd / vcs_mean
) %>%
  mutate(ID = as.numeric(as.character(ID)))

```

Filter and align certified assessments to the same format as the West 2024 data, then combine the two datasets. 


```{r}

cf_summary<-cf_vcs_comp_def %>%
  select(ID, VERRA, cf_source, cf_avd) %>%
  mutate(ID = ID %>% as.character() %>% as.numeric()) %>%
  # rbind(cf_934_comp_def) %>%
  filter(ID %in% c(934, 944, 1112, 1396)) %>%
  rename(avd_def_yr = cf_avd) %>%
  group_by(ID) %>%
  mutate(n = sum(!is.na(avd_def_yr))) %>%
  summarise(VERRA = VERRA[1],
            cf_n = n[1],
            cf_mean = mean(avd_def_yr, na.rm = TRUE),
            cf_min = min(avd_def_yr, na.rm = TRUE),
            cf_max = max(avd_def_yr, na.rm = TRUE),
            cf_sd = sd(avd_def_yr, na.rm = TRUE),
            cf_se = cf_sd / sqrt(n[1])
)

joint_summary<-inner_join(cf_summary, tw_summary)
tw_summary<-inner_join(tw_avd_def_yr, cf_summary)


joint_summary %<>% mutate(cf_n = 
                            as.factor(cf_n) %>%
                            fct_expand("1") %>% 
                            fct_inseq())

```

```{r}
# Counterfactual data
# - subset to projects with West evaluations of ex ante additionality
cf_subset<-cf_vcs_comp_def %>%
  select(ID, cf_source, cf_avd) %>%
  mutate(ID = ID %>% as.character() %>% as.numeric()) %>%
  # rbind(cf_934_comp_def) %>%
  filter(ID %in% c(934, 944, 1112, 1396)) %>%
  rename(avd_def_yr = cf_avd) %>%
  mutate(type = 'cf') %>%
  group_by(ID)

# West VCS data
tw_subset<-tw_avd_def_yr %>%
  select(ID, cf_source = methodology, avd_def_yr) %>%
  mutate(type = 'VCS') %>%
  group_by(ID)

# combine
joint_subset<-rbind(cf_subset, tw_subset)

# from the summary table extract the certifedvalues:
vcs_subset<-joint_summary %>%
  select(ID, VERRA, vcs_official) %>%
  pivot_longer(cols = c(VERRA, vcs_official), names_to = 'cf_source', values_to = 'avd_def_yr') %>%
  mutate(type = 'VCS') %>%
  mutate(ID = as.factor(ID))


joint_error<-bind_rows(
  joint_summary %>% select(ID, mean = cf_mean, se = cf_se) %>% mutate(type = 'cf'),
  joint_summary %>% select(ID, mean = vcs_mean, se = vcs_se) %>% mutate(type = 'VCS')
) %>%
  mutate(ID = as.factor(ID)) %>%
  mutate(type = fct_relevel(type, 'VCS')) %>%
  mutate(lower = mean - se * 1.96, upper = mean + se * 1.96)


joint_subset %>%
  filter(!cf_source %in% c('SC','official')) %>%
  mutate(ID = as.factor(ID)) %>%
  mutate(type = fct_relevel(type, 'VCS')) %>%
  # mutate(ID = fct_reorder(ID, cf_mean)) %>%
  ggplot(aes(x = ID, color = type)) +
  geom_hline(yintercept = 0) +
  # geom_boxplot(outlier.colour = NA) +
  geom_errorbar(data = joint_error, 
                aes(ymin = lower, ymax = upper), 
                position = position_dodge(width = 0.8),
                width = 0.2, 
                linewidth = 0.5, alpha = 0.7) +
  geom_point(aes(y = avd_def_yr), position = position_jitterdodge(0.6), shape = 1, alpha = 0.8, size = 3) +
#  geom_point(data = vcs_subset %>% filter(cf_source == 'VERRA'), aes(y = avd_def_yr, shape = cf_source), size = 3, alpha = 1, position = position_nudge(x = - 0.2)) +
  geom_point(data = vcs_subset %>% filter(cf_source == 'VERRA'), aes(y = avd_def_yr), shape = 16, size = 3, alpha = 1, position = position_nudge(x = - 0.2)) +

  scale_shape_manual(values = c(16,17), labels = c("vcs_official", "VERRA")) +    
  scale_color_manual(values = c('red', 'blue'), labels = c("Certified", "QEM")) +    
  ylab('Avoided deforestation (ha/year)') +
  xlab('Project')

ggsave(file.path(fig_path,'Variation in VCS vs counterfactual avoided deforestation_boxplot.png'),
       bg = 'white',
       width = 6,
       height = 5,
       units = 'in'
       )

```
##### ABBY EDITS ######


```{r}

joint_subset %>%
  filter(!cf_source %in% c('SC','official')) %>%
  mutate(ID = as.factor(ID)) %>%
  mutate(type = fct_relevel(type, 'VCS')) %>%
  # mutate(ID = fct_reorder(ID, cf_mean)) %>%
  ggplot(aes(x = ID, color = type)) +
  geom_hline(yintercept = 0) +
  # geom_boxplot(outlier.colour = NA) +
  geom_boxplot(mapping=aes(y=avd_def_yr),position = position_dodge(width = 0.8)) +
  geom_point(aes(y = avd_def_yr), position = position_jitterdodge(0.6), shape = 1, alpha = 0.8, size = 3) +
#  geom_point(data = vcs_subset %>% filter(cf_source == 'VERRA'), aes(y = avd_def_yr, shape = cf_source), size = 3, alpha = 1, position = position_nudge(x = - 0.2)) +
  geom_point(data = vcs_subset %>% filter(cf_source == 'VERRA'), aes(y = avd_def_yr), shape = 16, size = 3, alpha = 1, position = position_nudge(x = - 0.2)) +

  scale_shape_manual(values = c(16,17), labels = c("vcs_official", "VERRA")) +    
  scale_color_manual(values = c('red', 'blue'), labels = c("Certified", "QEM")) +    
  ylab('Avoided deforestation (ha/year)') +
  xlab('Project')

```

```{r}

# Making pooled error

pooled_error <- joint_subset %>% 
  mutate(type='Pooled')

joint_subset %>%
  bind_rows(pooled_error) %>% 
  filter(!cf_source %in% c('SC','official')) %>%
  mutate(ID = as.factor(ID)) %>%
  mutate(type = fct_relevel(type, 'Pooled', 'VCS')) %>%
  # mutate(ID = fct_reorder(ID, cf_mean)) %>%
  ggplot(aes(x = ID, color = type)) +
  geom_hline(yintercept = 0) +
  # geom_boxplot(outlier.colour = NA) +
  geom_boxplot(mapping=aes(y=avd_def_yr),position = position_dodge(width = 0.8)) +
  #geom_point(aes(y = avd_def_yr), position = position_jitterdodge(0.6), shape = 1, alpha = 0.8, size = 3) +
#  geom_point(data = vcs_subset %>% filter(cf_source == 'VERRA'), aes(y = avd_def_yr, shape = cf_source), size = 3, alpha = 1, position = position_nudge(x = - 0.2)) +
  geom_point(data = vcs_subset %>% filter(cf_source == 'VERRA'), aes(y = avd_def_yr), shape = 16, size = 3, alpha = 1, position = position_nudge(x = - 0.2)) +
  scale_shape_manual(values = c(16,17), labels = c("vcs_official", "VERRA")) +    
  scale_color_manual(values = c('magenta4', 'red', 'blue'), labels = c("Pooled", "VCS", "QEM")) +    
  ylab('Avoided deforestation (ha/year)') +
  xlab('Project')


```





Assessing the ratio of the average standard errors from certified vs statistical approaches

```{r}
vcs_summary<-joint_subset %>% 
  filter(type == 'VCS', 
         cf_source != 'SC') %>%
  group_by(ID) %>%
  summarise(n = n(),
            cf_avd_mean = mean(avd_def_yr),
            cf_avd_min = min(avd_def_yr),
            cf_avd_max = max(avd_def_yr),
            cf_avd_sd = sd(avd_def_yr),
            cf_avd_se = cf_avd_sd / sqrt(n)
            ) %>%
  mutate(cv = abs(cf_avd_sd / cf_avd_mean)) %>%
  mutate(range = abs(cf_avd_max - cf_avd_min))

cf_summary<-joint_subset %>% 
  filter(type == 'cf') %>%
  group_by(ID) %>%
  summarise(n = n(),
            cf_avd_mean = mean(avd_def_yr),
            cf_avd_min = min(avd_def_yr),
            cf_avd_max = max(avd_def_yr),
            cf_avd_sd = sd(avd_def_yr),
            cf_avd_se = cf_avd_sd / sqrt(n)
            ) %>%
  mutate(cv = abs(cf_avd_sd / cf_avd_mean)) %>%
  mutate(range = abs(cf_avd_max - cf_avd_min))

vcs_summary
cf_summary


se_vcs<-vcs_summary %>% 
  pull(cf_avd_se)

mean(se_vcs)                                                     # mean
mean(se_vcs) + c(-1, 1) * sd(se_vcs) / sqrt(length(se_vcs))*1.96 # 95% CI

se_cf<-cf_summary %>% 
  pull(cf_avd_se)

mean(se_cf)                                                     # mean
mean(se_cf) + c(-1, 1) * sd(se_cf) / sqrt(length(se_cf))*1.96 # 95% CI


vcs_summary$cf_avd_se
cf_summary$cf_avd_se

mean(se_vcs) / mean(se_cf)

```
Calculate the average ratio of the ranges

```{r}
inner_join(
  vcs_summary %>% select(ID, cv, range) %>% mutate(ID = as.character(ID)),
  cf_summary %>% select(ID, cv, range) %>% mutate(ID = as.character(ID)),
  by = "ID"
)%>%
  mutate(range_ratio = range.x / range.y) %>%
  summarise(mean(range_ratio))
```

Assess the probability of picking methods that produce the kth estimate out of n options for each project as well as the joint probability across the 4 projects. 

```{r}
choice<-1

cherry_picking_prob<-
  
  # tw_avd_def_yr %>%
  # filter(methodology != 'SC') %>%
  # select(-year_start, -year_end) %>%
  rbind(tw_subset %>% filter(!cf_source %in% c('SC','official')), 
      vcs_subset %>% 
        filter(cf_source == 'VERRA') %>%
      mutate(ID = as.character(ID) %>% as.numeric(),
             cf_source = 'official')
      ) %>%
  rename(methodology = cf_source) %>%
  
  pivot_wider(names_from = ID, values_from = avd_def_yr) %>%
  mutate(across(c(`934`, `944`, `1112`, `1396`), ~rank(.x))) %>%
  pivot_longer(cols = c(`934`, `944`, `1112`, `1396`), names_to = 'ID', values_to = 'rank') %>%
  group_by(ID) %>%
  arrange(ID) %>%
  mutate(n = n(),
         rank = n - rank + 1,
         prob = 1 - choose(n - choice, rank) / choose(n, rank) # which is the same as rank / n; although 
  ) %>%
  filter(methodology == 'official') %>%
  ungroup()

cherry_picking_prob


cherry_picking_prob %>%
  summarise(prob = prod(prob))
```
